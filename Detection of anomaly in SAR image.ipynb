{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Flatten, Activation\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers. Params. Preprocesing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_generator(generator):\n",
    "    for batch in generator:\n",
    "        yield (batch, batch)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test any image\n",
    "def IsImageHasAnomaly(autoencoder, filePath,threshold):  \n",
    "    im = cv2.resize(cv2.imread(filePath), (420, 420))\n",
    "    im = im * 1./255\n",
    "    datas = np.zeros((1,  420, 420, 3))\n",
    "    validation_image[0, :, :, :] = im;   \n",
    "    predicted_image = autoencoder.predict(validation_image)\n",
    "    _mse = mse(predicted_image[0], validation_image[0]) \n",
    "    print('_mse: {}'.format(_mse))\n",
    "    return _mse  > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 420, 420\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "nb_validation_samples=0\n",
    "nb_train_samples=0\n",
    "\n",
    "nb_epoch=20\n",
    "\n",
    "initial_image_dir='images\\\\docs'\n",
    "train_data_dir = initial_image_dir + '\\\\train'\n",
    "validation_data_dir = initial_image_dir + '\\\\valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator for images to complete dataset\n",
    "Generator is used for extending the image dataset by image transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New image generation flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate additional images for train in: images\\docs\\train\\correct_samples\n",
      "generate additional images for validation in: images\\docs\\valid\\correct_samples\n",
      "generate additional images for train in: images\\docs\\train\\correct_samples\n",
      "generate additional images for validation in: images\\docs\\valid\\correct_samples\n",
      "generate additional images for train in: images\\docs\\train\\correct_samples\n",
      "generate additional images for validation in: images\\docs\\valid\\correct_samples\n",
      "generate additional images for train in: images\\docs\\train\\correct_samples\n",
      "generate additional images for validation in: images\\docs\\valid\\correct_samples\n",
      "generate additional images for train in: images\\docs\\train\\correct_samples\n",
      "generate additional images for validation in: images\\docs\\valid\\correct_samples\n",
      "generate additional images for train in: images\\docs\\train\\correct_samples\n",
      "generate additional images for validation in: images\\docs\\valid\\correct_samples\n",
      "generate additional images for train in: images\\docs\\train\\correct_samples\n",
      "generate additional images for validation in: images\\docs\\valid\\correct_samples\n",
      "generate additional images for train in: images\\docs\\train\\correct_samples\n",
      "generate additional images for validation in: images\\docs\\valid\\correct_samples\n",
      "generate additional images for train in: images\\docs\\train\\correct_samples\n",
      "generate additional images for validation in: images\\docs\\valid\\correct_samples\n",
      "generate additional images for train in: images\\docs\\train\\correct_samples\n",
      "generate additional images for validation in: images\\docs\\valid\\correct_samples\n",
      "-------------------------------------------\n",
      "Initial image count: 10 \n",
      "Train image count: 607 \n",
      "Validation image count: 150 \n"
     ]
    }
   ],
   "source": [
    "image_list = os.listdir(initial_image_dir) #initial path to images\n",
    "\n",
    "inital_image_count=0\n",
    "for img in image_list:   \n",
    "    img_path= initial_image_dir + '\\\\' + img\n",
    "    if not os.path.isfile(img_path):\n",
    "        continue\n",
    "       \n",
    "    inital_image_count += 1  \n",
    "    \n",
    "    img = load_img(img_path)  # this is a PIL image\n",
    "    x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "    x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "    \n",
    "    train_save_to = train_data_dir + '\\\\correct_samples'\n",
    "    if not os.path.exists(train_save_to):\n",
    "        os.makedirs(train_save_to)\n",
    "    \n",
    "    valid_save_to = validation_data_dir + '\\\\correct_samples'\n",
    "    if not os.path.exists(valid_save_to):\n",
    "        os.makedirs(valid_save_to)\n",
    "    \n",
    "    print(\"generate additional images for train in: \" + train_save_to)\n",
    "    \n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=5, save_to_dir = train_save_to, save_prefix='sample', save_format='jpeg'):\n",
    "        i += 1\n",
    "        if i > 20:\n",
    "            break  # otherwise the generator would loop indefinitely\n",
    "\n",
    "    train_size=0            \n",
    "    for t in os.listdir(train_save_to):\n",
    "        if os.path.isfile(train_save_to +\"\\\\\" + t):\n",
    "            train_size += 1 \n",
    "            \n",
    "            \n",
    "    print(\"generate additional images for validation in: \" + valid_save_to)\n",
    "    ii=0\n",
    "    for batch in datagen.flow(x, batch_size=1, save_to_dir=valid_save_to, save_prefix='doc', save_format='jpeg'):\n",
    "        ii += 1\n",
    "        if ii > 4:\n",
    "            break  # otherwise the generator would loop indefinitely\n",
    "            \n",
    "    validation_size=0            \n",
    "    for v in os.listdir(valid_save_to):\n",
    "        if os.path.isfile(valid_save_to+\"\\\\\" +v):\n",
    "            validation_size += 1 \n",
    "            \n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Initial image count: {} \".format(inital_image_count))\n",
    "print(\"Train image count: {} \".format(train_size))\n",
    "print(\"Validation image count: {} \".format(validation_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exract data for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 607 images belonging to 1 classes.\n",
      "Found 150 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "# only rescaling\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,  # this is the target directory\n",
    "        target_size=(img_width, img_height),  \n",
    "        batch_size=batch_size,\n",
    "        color_mode='rgb', \n",
    "        class_mode=None)  \n",
    "\n",
    "nb_train_samples=train_generator.samples\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        color_mode='rgb', \n",
    "        class_mode=None)\n",
    "\n",
    "nb_validation_samples=validation_generator.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Simplest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 420, 420, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 420, 420, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 210, 210, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 210, 210, 8)       1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 105, 105, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 105, 105, 8)       584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 53, 53, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 53, 53, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2 (None, 106, 106, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 106, 106, 8)       584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (None, 212, 212, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 210, 210, 16)      1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 420, 420, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 420, 420, 3)       435       \n",
      "=================================================================\n",
      "Total params: 4,963\n",
      "Trainable params: 4,963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(batch_shape=(None, img_width, img_width, 3))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 291s 16s/step - loss: 0.4760 - val_loss: 0.3653\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 280s 16s/step - loss: 0.3578 - val_loss: 0.3466\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 280s 16s/step - loss: 0.3482 - val_loss: 0.3541\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 281s 16s/step - loss: 0.3449 - val_loss: 0.3652\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 281s 16s/step - loss: 0.3427 - val_loss: 0.3360\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 280s 16s/step - loss: 0.3428 - val_loss: 0.3417\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 283s 16s/step - loss: 0.3473 - val_loss: 0.3420\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 280s 16s/step - loss: 0.3432 - val_loss: 0.3374\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 282s 16s/step - loss: 0.3292 - val_loss: 0.3360\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 280s 16s/step - loss: 0.3348 - val_loss: 0.3695\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 309s 17s/step - loss: 0.3321 - val_loss: 0.3338\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 332s 18s/step - loss: 0.3302 - val_loss: 0.3182\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 360s 20s/step - loss: 0.3312 - val_loss: 0.3110\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 341s 19s/step - loss: 0.3220 - val_loss: 0.3244\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 320s 18s/step - loss: 0.3291 - val_loss: 0.3268\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 330s 18s/step - loss: 0.3221 - val_loss: 0.3184\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 293s 16s/step - loss: 0.3197 - val_loss: 0.3146\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 331s 18s/step - loss: 0.3216 - val_loss: 0.3497\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 321s 18s/step - loss: 0.3076 - val_loss: 0.3023\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 312s 17s/step - loss: 0.3164 - val_loss: 0.3257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16ebf7907f0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit_generator(\n",
    "        fixed_generator(train_generator),\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=nb_epoch,\n",
    "        validation_data=fixed_generator(validation_generator),\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights('anomaly-detection.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights('anomaly-detection.h5');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test encoder and visualize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(validation_generator)[:7] # Get rendom image\n",
    "\n",
    "dec = autoencoder.predict(img) # Decoded image\n",
    "img = img[0]\n",
    "dec = dec[0]\n",
    "img = (img*255).astype('uint8')\n",
    "dec = (dec*255).astype('uint8')\n",
    "\n",
    "plt.imshow(np.hstack((img, dec)))\n",
    "plt.title('Original and reconstructed images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visual result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of using mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1>2>3>4>5>6>7>8>9>10>11>12>13>14>15>16>17>18>19>20>21>22>23>24>25>26>27>28>29>30>31>32>33>34>35>36>37>38>39>40>41>42>43>44>45>46>47>48>49>50>51>52>53>54>55>56>57>58>59>60>61>62>63>64>65>66>67>68>69>70>71>72>73>74>75>76>77>78>79>80>81>82>83>84>85>86>87>88>89>90>91>92>93>94>95>96>97>98>99>100>101>102>103>104>105>106>107>108>109>110>111>112>113>114>115>116>117>118>119>120>121>122>123>124>125>126>127>128>129>130>131>132>133>134>135>136>137>138>139>140>141>142>143>144>145>146>147>148>149>150>"
     ]
    }
   ],
   "source": [
    "#collect all mse-s\n",
    "all_mses=[]\n",
    "step=1;\n",
    "for validation_image in validation_generator:   \n",
    "    if step>nb_validation_samples:\n",
    "        break;\n",
    "        \n",
    "    print(step, sep=' ', end='>', flush=True)       \n",
    "    predicted_image = autoencoder.predict(validation_image)\n",
    "    mse_value= mse(predicted_image[0], validation_image[0])\n",
    "    all_mses.append(mse_value)\n",
    "    step=step+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reconstruction_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.056851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.041283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.066063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.082397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.107733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.270635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reconstruction_error\n",
       "count            150.000000\n",
       "mean               0.100630\n",
       "std                0.056851\n",
       "min                0.041283\n",
       "25%                0.066063\n",
       "50%                0.082397\n",
       "75%                0.107733\n",
       "max                0.270635"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df = pd.DataFrame({'reconstruction_error':all_mses})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16e88a3c748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "_ = ax.hist(error_df.reconstruction_error.values, bins=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Selecting th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base on visulization lets say that everething that more then 0.14 likelihood anomaly\n",
    "# set threshold manually\n",
    "threshold=0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_mse: 0.0670472955415333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IsImageHasAnomaly(autoencoder, 'original.jpg',threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
